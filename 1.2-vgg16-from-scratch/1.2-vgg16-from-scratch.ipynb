{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG (Visual Geometry Group, University of Oxford) #\n",
    "\n",
    "![VGGimage](https://www.cs.toronto.edu/~frossard/post/vgg16/vgg16.png)\n",
    "\n",
    "VGG paper [VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION](https://arxiv.org/pdf/1409.1556v6.pdf)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "The NN structure\n",
    "<br>\n",
    "![vggstructure](https://cdn-images-1.medium.com/max/1600/1*FRd9fDM1TXThW2V8ylL7VQ.png)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "According to the essay's test, D (VGG16) and E (VGG19) are the best results. Since the methods and skills of constructing these two networks are almost the same, we construct D (VGG16) network structure type.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "![architecture](https://cdn-images-1.medium.com/max/1600/1*DwsWBmGCI7qL9ei7n_SdXA.png)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* 輸入圖像尺寸(input size)：224 x 224\n",
    "* 感受過瀘器(receptive field)的大小是3 x 3\n",
    "* 卷積步長(stride)是1個像素\n",
    "* 填充(padding)是1（對於3 x 3的感受過瀘器）\n",
    "* 池化層的大小是2×2且步長(stride)為2像素\n",
    "* 有兩個完全連接層，每層4096個神經元\n",
    "* 最後一層是具有1000個神經元的softmax分類層（代表1000個ImageNet類別）\n",
    "* 激勵函數是ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Windows-10-10.0.16299-SP0\n",
      "Tensorflow version: 1.4.0\n",
      "Keras version: 2.0.8\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import tensorflow\n",
    "import keras\n",
    "print(\"Platform: {}\".format(platform.platform()))\n",
    "print(\"Tensorflow version: {}\".format(tensorflow.__version__))\n",
    "print(\"Keras version: {}\".format(keras.__version__))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Input\n",
    "input_shape = (224, 224, 3) # RGB image 224x224 (height, width, channel)\n",
    "\n",
    "# Sequential\n",
    "model = Sequential(name='vgg16-sequential')\n",
    "\n",
    "# The first convolution block (block1)\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=input_shape, name='block1_conv1'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu', name='block1_conv2'))\n",
    "model.add(MaxPool2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "# The second convolution block (block2)\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu', name='block2_conv1'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu', name='block2_conv2'))\n",
    "model.add(MaxPool2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "# The 3rd convolution block (block3)\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu', name='block3_conv1'))\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu', name='block3_conv2'))\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu', name='block3_conv3'))\n",
    "model.add(MaxPool2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "# The 4th convolution block (block4)\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu', name='block4_conv1'))\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu', name='block4_conv2'))\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu', name='block4_conv3'))\n",
    "model.add(MaxPool2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "# The 5th convolution block (block5)\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu', name='block5_conv1'))\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu', name='block5_conv2'))\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu', name='block5_conv3'))\n",
    "model.add(MaxPool2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
    "\n",
    "# Feedforward full connection block\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(4096, activation='relu', name='fc1'))\n",
    "model.add(Dense(4096, activation='relu', name='fc2'))\n",
    "model.add(Dense(1000, activation='softmax', name='predictions'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functaional API #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img_input (InputLayer)       (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "\n",
    "# input\n",
    "input_shape = (224, 224, 3) # RGB image 224x224 (height, width, channel)\n",
    "\n",
    "# Input layer\n",
    "img_input = Input(shape=input_shape, name='img_input')\n",
    "\n",
    "# The first convolution block (block1)\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu', name='block1_conv1')(img_input)\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu', name='block1_conv2')(x)\n",
    "x = MaxPool2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# The second convolution block (block2)\n",
    "x = Conv2D(128, (3, 3), padding='same', activation='relu', name='block2_conv1')(x)\n",
    "x = Conv2D(128, (3, 3), padding='same', activation='relu', name='block2_conv2')(x)\n",
    "x = MaxPool2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "# The 3rd convolution block (block3)\n",
    "x = Conv2D(256, (3, 3), padding='same', activation='relu', name='block3_conv1')(x)\n",
    "x = Conv2D(256, (3, 3), padding='same', activation='relu', name='block3_conv2')(x)\n",
    "x = Conv2D(256, (3, 3), padding='same', activation='relu', name='block3_conv3')(x)\n",
    "x = MaxPool2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "# The 4th convolution block (block4)\n",
    "x = Conv2D(512, (3, 3), padding='same', activation='relu', name='block4_conv1')(x)\n",
    "x = Conv2D(512, (3, 3), padding='same', activation='relu', name='block4_conv2')(x)\n",
    "x = Conv2D(512, (3, 3), padding='same', activation='relu', name='block4_conv3')(x)\n",
    "x = MaxPool2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "# The 5th convolution block (block5)\n",
    "x = Conv2D(512, (3, 3), padding='same', activation='relu', name='block5_conv1')(x)\n",
    "x = Conv2D(512, (3, 3), padding='same', activation='relu', name='block5_conv2')(x)\n",
    "x = Conv2D(512, (3, 3), padding='same', activation='relu', name='block5_conv3')(x)\n",
    "x = MaxPool2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "# Feedforward full connection block\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "# Model\n",
    "model2 = Model(inputs=img_input, outputs=x, name='vgg16-funcapi')\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training #\n",
    "\n",
    "Using ImageNet's data to train a VGG16 model is not an easy task.\n",
    "\n",
    "The paper point:\n",
    "> On a system equipped with four NVIDIA Titan Black GPUs, training a single net took 2–3 weeks depending on the architecture.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Fortunately, not only has Keras already included the model definitions of VGG16 and VGG19 in its modules, it also pre-trained the model weights of VGG16 and VGG19.\n",
    "\n",
    "[Keras Documentation in VGG16](https://keras.io/applications/#vgg16)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Reference:\n",
    "\n",
    "[Learning Keras by Implementing the VGG Network From Scratch](https://hackernoon.com/learning-keras-by-implementing-vgg16-from-scratch-d036733f2d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
