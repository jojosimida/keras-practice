{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is sequence-to-sequence learning?\n",
    "\n",
    "Sequence-to-sequence learning (Seq2Seq) is about training models to convert sequences from one domain (e.g. sentences in English) to sequences in another domain (e.g. the same sentences translated to French).\n",
    "\n",
    "![ex](https://imgur.com/XwREty3.jpg)\n",
    "\n",
    "      \"the cat sat on the mat\" -> [Seq2Seq model] -> \"那隻貓坐在地毯上\" \n",
    "      \n",
    "This can be used for machine translation or for free-from question answering (generating a natural language answer given a natural language question) -- in general, it is applicable any time you need to generate text.\n",
    "\n",
    "There are multiple ways to handle this task, either using RNNs or using 1D convnets. Here we will focus on RNNs.\n",
    "\n",
    "## The trivial case: when input and output sequences have the same length\n",
    "\n",
    "When both input sequences and output sequences have the same length, you can implement such models simply with a Keras LSTM or GRU layer (or stack thereof). This is the case in this example script that shows how to teach a RNN to learn to add numbers, encoded as character strings:\n",
    "\n",
    "![LSTM](https://blog.keras.io/img/seq2seq/addition-rnn.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"\n",
    "     Give a group of characters:\n",
    "     + Encode these characters using one-hot encoding into numbers\n",
    "     + Decode one-hot encoded digits to be the original character\n",
    "     + Decode the probability of a character to answer the most likely character\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"\n",
    "        Initialize character table\n",
    "        \n",
    "         # Parameters:\n",
    "             chars: Appears in the possible character set entered\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        \n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"\n",
    "        Enter the string one-hot encoding\n",
    "        \n",
    "         # Parameters:\n",
    "             C: The character to be encoded\n",
    "             num_rows: The maximum number of lines to be returned after one-hot encoding. \n",
    "                       This is to make sure that every input is there\n",
    "                       The same number of lines of output\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"\n",
    "        The input code (vector) is decoded\n",
    "        \n",
    "         # Parameters:\n",
    "             x: character vector or character encoding to be decoded\n",
    "             calc_argmax: Whether to use the argmax operator to find the most likely character encoding\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "    \n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant parameters and training data set generated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "# Model and data set parameters\n",
    "TRAINING_SIZE = 50000 \n",
    "DIGITS = 3            \n",
    "INVERT = True \n",
    "\n",
    "# the maximum length of enter: 'int + int' (ex, '345+678')\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All characters to use (including numbers, plus signs and spaces)\n",
    "chars = '0123456789+ '\n",
    "# Create CharacterTable instance\n",
    "ctable = CharacterTable(chars) \n",
    "\n",
    "# Training sentence \"xxx + yyy\"\n",
    "questions = [] \n",
    "# Training label\n",
    "expected = []  \n",
    "seen = set()\n",
    "\n",
    "print('Generating data...') # 產生訓練資料\n",
    "\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    # Number Generator (3 characters)\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                           for i in range(np.random.randint(1, DIGITS+1))))\n",
    "    a, b = f(), f()\n",
    "    \n",
    "    # Skip the topics that have been seen and x + Y = Y + x this problem\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue    \n",
    "    seen.add(key)\n",
    "    \n",
    "    # When the number is less than MAXLEN then fill the blank\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    \n",
    "    # The maximum character length of the answer is DIGITS + 1\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    \n",
    "    if INVERT:\n",
    "        # To reverse the direction of the problem character, eg '12 +345 'becomes' 543 + 21'\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "    \n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Feature data:  (50000, 7, 12)\n",
      "Label data:  (50000, 4, 12)\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "# The appropriate conversion of data, LSTM expected data structure -> [samples, timesteps, features]\n",
    "print('Vectorization...')\n",
    "\n",
    "# The initial three-dimensional numpy ndarray (characteristic data)\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool) \n",
    "# Initially a 3-D numpy ndarray (label information)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool) \n",
    "\n",
    "# Convert \"feature data\" into the LSTM's expected data structure -> [samples, timesteps, features]\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)      \n",
    "\n",
    "print(\"Feature data: \", x.shape)\n",
    "\n",
    "# Convert \"label data\" into the LSTM's expected data structure -> [samples, timesteps, features]\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)  \n",
    "\n",
    "print(\"Label data: \", y.shape)\n",
    "\n",
    "# Shuffle(x, y)\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Retain 10% of the information for verification\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a network infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try to replace other rnn units, such as GRU or SimpleRNN\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# ===== encoder ====\n",
    "\n",
    "# Generate the output of HIDDEN_SIZE using the RNN \"code\" input sequence.\n",
    "# Note: With input sequence length variable, use input_shape = (None, num_features)\n",
    "\n",
    "# MAXLEN stands for timesteps, len (chars) is one-hot-coded features\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars)))) \n",
    "\n",
    "# As input to the decoder RNN, the last hidden state of the RNN providing each time step is repeated.\n",
    "# Repeat \"DIGITS + 1\" times because this is the maximum output length, for example, when DIGITS = 3, \n",
    "# the maximum output is 999 + 999 = 1998 (length 4).\n",
    "model.add(layers.RepeatVector(DIGITS+1))\n",
    "\n",
    "\n",
    "# ==== decoder ====\n",
    "# The decoder RNNs can be multi-layer stacks or single layers.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, not only the last output is returned, but also all outputs are returned as \n",
    "    # (num_samples, timesteps, output_dim). This is necessary because the following TimeDistributed requires that the \n",
    "    # first dimension be a time step.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Each entered time slice is pushed to the dense layer to decide which character to select \n",
    "# for each time step of the output sequence.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model / Verification Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 16s 349us/step - loss: 1.8879 - acc: 0.3219 - val_loss: 1.7729 - val_acc: 0.3433\n",
      "Q 623+449 T 1072 \u001b[91m☒\u001b[0m 103 \n",
      "Q 959+26  T 985  \u001b[91m☒\u001b[0m 109 \n",
      "Q 518+41  T 559  \u001b[91m☒\u001b[0m 101 \n",
      "Q 34+850  T 884  \u001b[91m☒\u001b[0m 108 \n",
      "Q 819+40  T 859  \u001b[91m☒\u001b[0m 109 \n",
      "Q 321+372 T 693  \u001b[91m☒\u001b[0m 108 \n",
      "Q 52+222  T 274  \u001b[91m☒\u001b[0m 111 \n",
      "Q 98+861  T 959  \u001b[91m☒\u001b[0m 109 \n",
      "Q 116+36  T 152  \u001b[91m☒\u001b[0m 111 \n",
      "Q 78+264  T 342  \u001b[91m☒\u001b[0m 107 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 213us/step - loss: 1.7275 - acc: 0.3620 - val_loss: 1.6632 - val_acc: 0.3806\n",
      "Q 960+999 T 1959 \u001b[91m☒\u001b[0m 1610\n",
      "Q 812+116 T 928  \u001b[91m☒\u001b[0m 102 \n",
      "Q 591+171 T 762  \u001b[91m☒\u001b[0m 102 \n",
      "Q 74+180  T 254  \u001b[91m☒\u001b[0m 177 \n",
      "Q 164+33  T 197  \u001b[91m☒\u001b[0m 276 \n",
      "Q 40+607  T 647  \u001b[91m☒\u001b[0m 576 \n",
      "Q 29+856  T 885  \u001b[91m☒\u001b[0m 696 \n",
      "Q 581+57  T 638  \u001b[91m☒\u001b[0m 555 \n",
      "Q 898+82  T 980  \u001b[91m☒\u001b[0m 902 \n",
      "Q 25+569  T 594  \u001b[91m☒\u001b[0m 556 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 210us/step - loss: 1.5858 - acc: 0.4058 - val_loss: 1.5028 - val_acc: 0.4293\n",
      "Q 928+979 T 1907 \u001b[91m☒\u001b[0m 1780\n",
      "Q 384+330 T 714  \u001b[91m☒\u001b[0m 802 \n",
      "Q 10+684  T 694  \u001b[91m☒\u001b[0m 175 \n",
      "Q 515+847 T 1362 \u001b[91m☒\u001b[0m 1252\n",
      "Q 95+43   T 138  \u001b[91m☒\u001b[0m 155 \n",
      "Q 249+40  T 289  \u001b[91m☒\u001b[0m 245 \n",
      "Q 807+5   T 812  \u001b[91m☒\u001b[0m 875 \n",
      "Q 506+978 T 1484 \u001b[91m☒\u001b[0m 1545\n",
      "Q 50+391  T 441  \u001b[91m☒\u001b[0m 355 \n",
      "Q 123+6   T 129  \u001b[91m☒\u001b[0m 226 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 224us/step - loss: 1.4094 - acc: 0.4736 - val_loss: 1.3295 - val_acc: 0.5008\n",
      "Q 91+190  T 281  \u001b[91m☒\u001b[0m 191 \n",
      "Q 498+82  T 580  \u001b[91m☒\u001b[0m 443 \n",
      "Q 636+302 T 938  \u001b[91m☒\u001b[0m 903 \n",
      "Q 429+258 T 687  \u001b[91m☒\u001b[0m 609 \n",
      "Q 51+633  T 684  \u001b[91m☒\u001b[0m 669 \n",
      "Q 71+47   T 118  \u001b[91m☒\u001b[0m 111 \n",
      "Q 140+745 T 885  \u001b[91m☒\u001b[0m 903 \n",
      "Q 347+408 T 755  \u001b[91m☒\u001b[0m 843 \n",
      "Q 610+380 T 990  \u001b[91m☒\u001b[0m 1003\n",
      "Q 407+119 T 526  \u001b[91m☒\u001b[0m 419 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 201us/step - loss: 1.2627 - acc: 0.5309 - val_loss: 1.1997 - val_acc: 0.5592\n",
      "Q 83+733  T 816  \u001b[91m☒\u001b[0m 811 \n",
      "Q 2+457   T 459  \u001b[91m☒\u001b[0m 451 \n",
      "Q 928+625 T 1553 \u001b[91m☒\u001b[0m 1548\n",
      "Q 537+817 T 1354 \u001b[91m☒\u001b[0m 1301\n",
      "Q 371+0   T 371  \u001b[91m☒\u001b[0m 388 \n",
      "Q 66+752  T 818  \u001b[91m☒\u001b[0m 731 \n",
      "Q 19+372  T 391  \u001b[91m☒\u001b[0m 311 \n",
      "Q 75+872  T 947  \u001b[91m☒\u001b[0m 941 \n",
      "Q 158+5   T 163  \u001b[91m☒\u001b[0m 158 \n",
      "Q 9+677   T 686  \u001b[91m☒\u001b[0m 771 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 232us/step - loss: 1.1455 - acc: 0.5786 - val_loss: 1.0894 - val_acc: 0.6009\n",
      "Q 8+903   T 911  \u001b[91m☒\u001b[0m 913 \n",
      "Q 740+34  T 774  \u001b[91m☒\u001b[0m 777 \n",
      "Q 376+39  T 415  \u001b[91m☒\u001b[0m 412 \n",
      "Q 4+947   T 951  \u001b[91m☒\u001b[0m 940 \n",
      "Q 950+324 T 1274 \u001b[91m☒\u001b[0m 1232\n",
      "Q 119+70  T 189  \u001b[91m☒\u001b[0m 182 \n",
      "Q 888+650 T 1538 \u001b[91m☒\u001b[0m 1503\n",
      "Q 872+7   T 879  \u001b[91m☒\u001b[0m 887 \n",
      "Q 269+83  T 352  \u001b[92m☑\u001b[0m 352 \n",
      "Q 81+350  T 431  \u001b[91m☒\u001b[0m 427 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 221us/step - loss: 1.0395 - acc: 0.6212 - val_loss: 0.9927 - val_acc: 0.6389\n",
      "Q 27+640  T 667  \u001b[91m☒\u001b[0m 675 \n",
      "Q 727+2   T 729  \u001b[92m☑\u001b[0m 729 \n",
      "Q 139+991 T 1130 \u001b[91m☒\u001b[0m 1106\n",
      "Q 875+22  T 897  \u001b[91m☒\u001b[0m 890 \n",
      "Q 558+70  T 628  \u001b[91m☒\u001b[0m 625 \n",
      "Q 1+368   T 369  \u001b[91m☒\u001b[0m 365 \n",
      "Q 740+1   T 741  \u001b[91m☒\u001b[0m 744 \n",
      "Q 27+61   T 88   \u001b[91m☒\u001b[0m 70  \n",
      "Q 671+287 T 958  \u001b[91m☒\u001b[0m 940 \n",
      "Q 394+322 T 716  \u001b[91m☒\u001b[0m 800 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 231us/step - loss: 0.9476 - acc: 0.6586 - val_loss: 0.9238 - val_acc: 0.6622\n",
      "Q 364+280 T 644  \u001b[91m☒\u001b[0m 626 \n",
      "Q 349+74  T 423  \u001b[91m☒\u001b[0m 427 \n",
      "Q 8+839   T 847  \u001b[91m☒\u001b[0m 846 \n",
      "Q 26+87   T 113  \u001b[91m☒\u001b[0m 116 \n",
      "Q 67+263  T 330  \u001b[91m☒\u001b[0m 324 \n",
      "Q 61+88   T 149  \u001b[91m☒\u001b[0m 156 \n",
      "Q 748+892 T 1640 \u001b[91m☒\u001b[0m 1636\n",
      "Q 677+57  T 734  \u001b[91m☒\u001b[0m 732 \n",
      "Q 5+616   T 621  \u001b[91m☒\u001b[0m 629 \n",
      "Q 447+406 T 853  \u001b[91m☒\u001b[0m 877 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 230us/step - loss: 0.8645 - acc: 0.6924 - val_loss: 0.8328 - val_acc: 0.7051\n",
      "Q 584+365 T 949  \u001b[91m☒\u001b[0m 943 \n",
      "Q 871+83  T 954  \u001b[91m☒\u001b[0m 955 \n",
      "Q 5+770   T 775  \u001b[91m☒\u001b[0m 778 \n",
      "Q 465+56  T 521  \u001b[92m☑\u001b[0m 521 \n",
      "Q 179+60  T 239  \u001b[91m☒\u001b[0m 248 \n",
      "Q 3+323   T 326  \u001b[92m☑\u001b[0m 326 \n",
      "Q 680+917 T 1597 \u001b[91m☒\u001b[0m 1680\n",
      "Q 809+458 T 1267 \u001b[91m☒\u001b[0m 1277\n",
      "Q 61+496  T 557  \u001b[91m☒\u001b[0m 551 \n",
      "Q 465+56  T 521  \u001b[92m☑\u001b[0m 521 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 213us/step - loss: 0.7863 - acc: 0.7224 - val_loss: 0.7472 - val_acc: 0.7400\n",
      "Q 973+597 T 1570 \u001b[91m☒\u001b[0m 1577\n",
      "Q 977+15  T 992  \u001b[91m☒\u001b[0m 990 \n",
      "Q 341+288 T 629  \u001b[91m☒\u001b[0m 628 \n",
      "Q 350+20  T 370  \u001b[91m☒\u001b[0m 373 \n",
      "Q 72+536  T 608  \u001b[91m☒\u001b[0m 508 \n",
      "Q 673+5   T 678  \u001b[91m☒\u001b[0m 679 \n",
      "Q 126+35  T 161  \u001b[92m☑\u001b[0m 161 \n",
      "Q 57+645  T 702  \u001b[91m☒\u001b[0m 601 \n",
      "Q 69+895  T 964  \u001b[91m☒\u001b[0m 962 \n",
      "Q 145+603 T 748  \u001b[91m☒\u001b[0m 655 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 213us/step - loss: 0.6789 - acc: 0.7632 - val_loss: 0.6085 - val_acc: 0.7840\n",
      "Q 260+740 T 1000 \u001b[91m☒\u001b[0m 1013\n",
      "Q 737+835 T 1572 \u001b[91m☒\u001b[0m 1573\n",
      "Q 123+682 T 805  \u001b[91m☒\u001b[0m 895 \n",
      "Q 388+4   T 392  \u001b[92m☑\u001b[0m 392 \n",
      "Q 80+687  T 767  \u001b[91m☒\u001b[0m 769 \n",
      "Q 140+745 T 885  \u001b[91m☒\u001b[0m 884 \n",
      "Q 899+747 T 1646 \u001b[91m☒\u001b[0m 1644\n",
      "Q 63+856  T 919  \u001b[92m☑\u001b[0m 919 \n",
      "Q 6+320   T 326  \u001b[91m☒\u001b[0m 325 \n",
      "Q 892+167 T 1059 \u001b[91m☒\u001b[0m 1054\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 214us/step - loss: 0.4950 - acc: 0.8365 - val_loss: 0.4186 - val_acc: 0.8658\n",
      "Q 54+118  T 172  \u001b[92m☑\u001b[0m 172 \n",
      "Q 976+5   T 981  \u001b[92m☑\u001b[0m 981 \n",
      "Q 313+68  T 381  \u001b[92m☑\u001b[0m 381 \n",
      "Q 255+7   T 262  \u001b[92m☑\u001b[0m 262 \n",
      "Q 908+915 T 1823 \u001b[91m☒\u001b[0m 1832\n",
      "Q 678+768 T 1446 \u001b[92m☑\u001b[0m 1446\n",
      "Q 95+937  T 1032 \u001b[92m☑\u001b[0m 1032\n",
      "Q 58+866  T 924  \u001b[92m☑\u001b[0m 924 \n",
      "Q 29+349  T 378  \u001b[91m☒\u001b[0m 377 \n",
      "Q 484+774 T 1258 \u001b[91m☒\u001b[0m 1269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 230us/step - loss: 0.3506 - acc: 0.9056 - val_loss: 0.3046 - val_acc: 0.9248\n",
      "Q 63+996  T 1059 \u001b[92m☑\u001b[0m 1059\n",
      "Q 779+96  T 875  \u001b[92m☑\u001b[0m 875 \n",
      "Q 929+430 T 1359 \u001b[92m☑\u001b[0m 1359\n",
      "Q 36+0    T 36   \u001b[91m☒\u001b[0m 47  \n",
      "Q 305+996 T 1301 \u001b[92m☑\u001b[0m 1301\n",
      "Q 854+7   T 861  \u001b[92m☑\u001b[0m 861 \n",
      "Q 98+649  T 747  \u001b[92m☑\u001b[0m 747 \n",
      "Q 669+683 T 1352 \u001b[92m☑\u001b[0m 1352\n",
      "Q 47+909  T 956  \u001b[92m☑\u001b[0m 956 \n",
      "Q 240+503 T 743  \u001b[91m☒\u001b[0m 742 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 235us/step - loss: 0.2629 - acc: 0.9411 - val_loss: 0.2290 - val_acc: 0.9520\n",
      "Q 317+43  T 360  \u001b[92m☑\u001b[0m 360 \n",
      "Q 81+509  T 590  \u001b[92m☑\u001b[0m 590 \n",
      "Q 294+17  T 311  \u001b[92m☑\u001b[0m 311 \n",
      "Q 27+92   T 119  \u001b[92m☑\u001b[0m 119 \n",
      "Q 232+53  T 285  \u001b[92m☑\u001b[0m 285 \n",
      "Q 22+426  T 448  \u001b[92m☑\u001b[0m 448 \n",
      "Q 711+516 T 1227 \u001b[92m☑\u001b[0m 1227\n",
      "Q 711+119 T 830  \u001b[91m☒\u001b[0m 820 \n",
      "Q 561+901 T 1462 \u001b[92m☑\u001b[0m 1462\n",
      "Q 211+313 T 524  \u001b[92m☑\u001b[0m 524 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 10s 214us/step - loss: 0.1969 - acc: 0.9624 - val_loss: 0.1781 - val_acc: 0.9648\n",
      "Q 779+3   T 782  \u001b[92m☑\u001b[0m 782 \n",
      "Q 28+203  T 231  \u001b[91m☒\u001b[0m 230 \n",
      "Q 144+554 T 698  \u001b[92m☑\u001b[0m 698 \n",
      "Q 89+71   T 160  \u001b[91m☒\u001b[0m 150 \n",
      "Q 512+68  T 580  \u001b[92m☑\u001b[0m 580 \n",
      "Q 413+61  T 474  \u001b[92m☑\u001b[0m 474 \n",
      "Q 599+0   T 599  \u001b[92m☑\u001b[0m 599 \n",
      "Q 30+892  T 922  \u001b[92m☑\u001b[0m 922 \n",
      "Q 61+725  T 786  \u001b[92m☑\u001b[0m 786 \n",
      "Q 954+6   T 960  \u001b[92m☑\u001b[0m 960 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 211us/step - loss: 0.1575 - acc: 0.9714 - val_loss: 0.1524 - val_acc: 0.9677\n",
      "Q 883+796 T 1679 \u001b[92m☑\u001b[0m 1679\n",
      "Q 603+39  T 642  \u001b[92m☑\u001b[0m 642 \n",
      "Q 246+4   T 250  \u001b[92m☑\u001b[0m 250 \n",
      "Q 256+66  T 322  \u001b[92m☑\u001b[0m 322 \n",
      "Q 483+72  T 555  \u001b[92m☑\u001b[0m 555 \n",
      "Q 509+65  T 574  \u001b[92m☑\u001b[0m 574 \n",
      "Q 669+683 T 1352 \u001b[92m☑\u001b[0m 1352\n",
      "Q 36+668  T 704  \u001b[92m☑\u001b[0m 704 \n",
      "Q 769+54  T 823  \u001b[92m☑\u001b[0m 823 \n",
      "Q 988+71  T 1059 \u001b[92m☑\u001b[0m 1059\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 227us/step - loss: 0.1301 - acc: 0.9760 - val_loss: 0.1472 - val_acc: 0.9621\n",
      "Q 197+947 T 1144 \u001b[91m☒\u001b[0m 1143\n",
      "Q 59+0    T 59   \u001b[92m☑\u001b[0m 59  \n",
      "Q 73+38   T 111  \u001b[92m☑\u001b[0m 111 \n",
      "Q 31+236  T 267  \u001b[92m☑\u001b[0m 267 \n",
      "Q 51+633  T 684  \u001b[92m☑\u001b[0m 684 \n",
      "Q 82+161  T 243  \u001b[92m☑\u001b[0m 243 \n",
      "Q 958+3   T 961  \u001b[92m☑\u001b[0m 961 \n",
      "Q 734+46  T 780  \u001b[92m☑\u001b[0m 780 \n",
      "Q 752+7   T 759  \u001b[92m☑\u001b[0m 759 \n",
      "Q 291+409 T 700  \u001b[91m☒\u001b[0m 790 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 220us/step - loss: 0.1066 - acc: 0.9807 - val_loss: 0.0987 - val_acc: 0.9819\n",
      "Q 645+888 T 1533 \u001b[92m☑\u001b[0m 1533\n",
      "Q 29+856  T 885  \u001b[92m☑\u001b[0m 885 \n",
      "Q 69+78   T 147  \u001b[92m☑\u001b[0m 147 \n",
      "Q 774+837 T 1611 \u001b[92m☑\u001b[0m 1611\n",
      "Q 34+50   T 84   \u001b[91m☒\u001b[0m 85  \n",
      "Q 486+570 T 1056 \u001b[92m☑\u001b[0m 1056\n",
      "Q 84+603  T 687  \u001b[92m☑\u001b[0m 687 \n",
      "Q 416+707 T 1123 \u001b[91m☒\u001b[0m 1133\n",
      "Q 36+51   T 87   \u001b[92m☑\u001b[0m 87  \n",
      "Q 8+341   T 349  \u001b[92m☑\u001b[0m 349 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 211us/step - loss: 0.0795 - acc: 0.9885 - val_loss: 0.0736 - val_acc: 0.9883\n",
      "Q 231+852 T 1083 \u001b[92m☑\u001b[0m 1083\n",
      "Q 665+80  T 745  \u001b[92m☑\u001b[0m 745 \n",
      "Q 709+307 T 1016 \u001b[92m☑\u001b[0m 1016\n",
      "Q 108+845 T 953  \u001b[92m☑\u001b[0m 953 \n",
      "Q 47+903  T 950  \u001b[92m☑\u001b[0m 950 \n",
      "Q 458+8   T 466  \u001b[92m☑\u001b[0m 466 \n",
      "Q 434+348 T 782  \u001b[92m☑\u001b[0m 782 \n",
      "Q 74+361  T 435  \u001b[92m☑\u001b[0m 435 \n",
      "Q 633+8   T 641  \u001b[92m☑\u001b[0m 641 \n",
      "Q 969+371 T 1340 \u001b[92m☑\u001b[0m 1340\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 213us/step - loss: 0.0775 - acc: 0.9860 - val_loss: 0.0623 - val_acc: 0.9903\n",
      "Q 171+443 T 614  \u001b[92m☑\u001b[0m 614 \n",
      "Q 258+882 T 1140 \u001b[92m☑\u001b[0m 1140\n",
      "Q 786+47  T 833  \u001b[92m☑\u001b[0m 833 \n",
      "Q 797+2   T 799  \u001b[92m☑\u001b[0m 799 \n",
      "Q 763+464 T 1227 \u001b[92m☑\u001b[0m 1227\n",
      "Q 82+385  T 467  \u001b[92m☑\u001b[0m 467 \n",
      "Q 84+90   T 174  \u001b[92m☑\u001b[0m 174 \n",
      "Q 207+22  T 229  \u001b[92m☑\u001b[0m 229 \n",
      "Q 699+854 T 1553 \u001b[92m☑\u001b[0m 1553\n",
      "Q 556+52  T 608  \u001b[92m☑\u001b[0m 608 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 210us/step - loss: 0.0522 - acc: 0.9940 - val_loss: 0.0545 - val_acc: 0.9914\n",
      "Q 599+0   T 599  \u001b[92m☑\u001b[0m 599 \n",
      "Q 90+47   T 137  \u001b[92m☑\u001b[0m 137 \n",
      "Q 74+634  T 708  \u001b[92m☑\u001b[0m 708 \n",
      "Q 860+447 T 1307 \u001b[92m☑\u001b[0m 1307\n",
      "Q 402+33  T 435  \u001b[92m☑\u001b[0m 435 \n",
      "Q 838+61  T 899  \u001b[92m☑\u001b[0m 899 \n",
      "Q 307+809 T 1116 \u001b[91m☒\u001b[0m 1115\n",
      "Q 23+95   T 118  \u001b[92m☑\u001b[0m 118 \n",
      "Q 2+10    T 12   \u001b[92m☑\u001b[0m 12  \n",
      "Q 543+140 T 683  \u001b[92m☑\u001b[0m 683 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 210us/step - loss: 0.0583 - acc: 0.9891 - val_loss: 0.0684 - val_acc: 0.9838\n",
      "Q 95+937  T 1032 \u001b[92m☑\u001b[0m 1032\n",
      "Q 41+209  T 250  \u001b[92m☑\u001b[0m 250 \n",
      "Q 35+44   T 79   \u001b[92m☑\u001b[0m 79  \n",
      "Q 786+6   T 792  \u001b[92m☑\u001b[0m 792 \n",
      "Q 282+829 T 1111 \u001b[92m☑\u001b[0m 1111\n",
      "Q 398+0   T 398  \u001b[92m☑\u001b[0m 398 \n",
      "Q 560+299 T 859  \u001b[91m☒\u001b[0m 759 \n",
      "Q 43+8    T 51   \u001b[92m☑\u001b[0m 51  \n",
      "Q 780+15  T 795  \u001b[92m☑\u001b[0m 795 \n",
      "Q 411+15  T 426  \u001b[92m☑\u001b[0m 426 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 210us/step - loss: 0.0445 - acc: 0.9930 - val_loss: 0.0552 - val_acc: 0.9869\n",
      "Q 365+661 T 1026 \u001b[92m☑\u001b[0m 1026\n",
      "Q 772+738 T 1510 \u001b[92m☑\u001b[0m 1510\n",
      "Q 324+612 T 936  \u001b[92m☑\u001b[0m 936 \n",
      "Q 565+7   T 572  \u001b[92m☑\u001b[0m 572 \n",
      "Q 219+384 T 603  \u001b[92m☑\u001b[0m 603 \n",
      "Q 158+415 T 573  \u001b[92m☑\u001b[0m 573 \n",
      "Q 771+69  T 840  \u001b[92m☑\u001b[0m 840 \n",
      "Q 243+40  T 283  \u001b[92m☑\u001b[0m 283 \n",
      "Q 9+578   T 587  \u001b[92m☑\u001b[0m 587 \n",
      "Q 426+3   T 429  \u001b[92m☑\u001b[0m 429 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 210us/step - loss: 0.0375 - acc: 0.9942 - val_loss: 0.0315 - val_acc: 0.9952\n",
      "Q 982+974 T 1956 \u001b[92m☑\u001b[0m 1956\n",
      "Q 486+98  T 584  \u001b[92m☑\u001b[0m 584 \n",
      "Q 409+135 T 544  \u001b[92m☑\u001b[0m 544 \n",
      "Q 431+971 T 1402 \u001b[92m☑\u001b[0m 1402\n",
      "Q 370+47  T 417  \u001b[92m☑\u001b[0m 417 \n",
      "Q 2+837   T 839  \u001b[92m☑\u001b[0m 839 \n",
      "Q 275+343 T 618  \u001b[92m☑\u001b[0m 618 \n",
      "Q 86+23   T 109  \u001b[92m☑\u001b[0m 109 \n",
      "Q 718+9   T 727  \u001b[92m☑\u001b[0m 727 \n",
      "Q 211+38  T 249  \u001b[92m☑\u001b[0m 249 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 210us/step - loss: 0.0260 - acc: 0.9974 - val_loss: 0.0353 - val_acc: 0.9933\n",
      "Q 33+69   T 102  \u001b[92m☑\u001b[0m 102 \n",
      "Q 284+3   T 287  \u001b[92m☑\u001b[0m 287 \n",
      "Q 755+271 T 1026 \u001b[92m☑\u001b[0m 1026\n",
      "Q 252+601 T 853  \u001b[92m☑\u001b[0m 853 \n",
      "Q 929+70  T 999  \u001b[91m☒\u001b[0m 199 \n",
      "Q 366+293 T 659  \u001b[92m☑\u001b[0m 659 \n",
      "Q 49+775  T 824  \u001b[92m☑\u001b[0m 824 \n",
      "Q 753+16  T 769  \u001b[92m☑\u001b[0m 769 \n",
      "Q 112+9   T 121  \u001b[92m☑\u001b[0m 121 \n",
      "Q 0+417   T 417  \u001b[92m☑\u001b[0m 417 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 211us/step - loss: 0.0534 - acc: 0.9864 - val_loss: 0.0256 - val_acc: 0.9960\n",
      "Q 495+194 T 689  \u001b[92m☑\u001b[0m 689 \n",
      "Q 66+380  T 446  \u001b[92m☑\u001b[0m 446 \n",
      "Q 41+958  T 999  \u001b[91m☒\u001b[0m 109 \n",
      "Q 32+846  T 878  \u001b[92m☑\u001b[0m 878 \n",
      "Q 8+628   T 636  \u001b[92m☑\u001b[0m 636 \n",
      "Q 46+527  T 573  \u001b[92m☑\u001b[0m 573 \n",
      "Q 23+37   T 60   \u001b[92m☑\u001b[0m 60  \n",
      "Q 852+953 T 1805 \u001b[92m☑\u001b[0m 1805\n",
      "Q 93+85   T 178  \u001b[92m☑\u001b[0m 178 \n",
      "Q 82+161  T 243  \u001b[92m☑\u001b[0m 243 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 209us/step - loss: 0.0187 - acc: 0.9986 - val_loss: 0.0221 - val_acc: 0.9968\n",
      "Q 22+255  T 277  \u001b[92m☑\u001b[0m 277 \n",
      "Q 28+96   T 124  \u001b[92m☑\u001b[0m 124 \n",
      "Q 226+42  T 268  \u001b[92m☑\u001b[0m 268 \n",
      "Q 532+608 T 1140 \u001b[92m☑\u001b[0m 1140\n",
      "Q 683+70  T 753  \u001b[92m☑\u001b[0m 753 \n",
      "Q 978+66  T 1044 \u001b[92m☑\u001b[0m 1044\n",
      "Q 946+738 T 1684 \u001b[92m☑\u001b[0m 1684\n",
      "Q 96+54   T 150  \u001b[92m☑\u001b[0m 150 \n",
      "Q 716+2   T 718  \u001b[92m☑\u001b[0m 718 \n",
      "Q 203+248 T 451  \u001b[92m☑\u001b[0m 451 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 214us/step - loss: 0.0465 - acc: 0.9879 - val_loss: 0.0443 - val_acc: 0.9877\n",
      "Q 525+60  T 585  \u001b[92m☑\u001b[0m 585 \n",
      "Q 681+1   T 682  \u001b[92m☑\u001b[0m 682 \n",
      "Q 73+51   T 124  \u001b[92m☑\u001b[0m 124 \n",
      "Q 0+140   T 140  \u001b[91m☒\u001b[0m 141 \n",
      "Q 729+432 T 1161 \u001b[92m☑\u001b[0m 1161\n",
      "Q 756+9   T 765  \u001b[92m☑\u001b[0m 765 \n",
      "Q 22+685  T 707  \u001b[92m☑\u001b[0m 707 \n",
      "Q 374+695 T 1069 \u001b[92m☑\u001b[0m 1069\n",
      "Q 50+0    T 50   \u001b[92m☑\u001b[0m 50  \n",
      "Q 880+588 T 1468 \u001b[92m☑\u001b[0m 1468\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 10s 211us/step - loss: 0.0186 - acc: 0.9978 - val_loss: 0.0195 - val_acc: 0.9967\n",
      "Q 64+427  T 491  \u001b[92m☑\u001b[0m 491 \n",
      "Q 594+262 T 856  \u001b[92m☑\u001b[0m 856 \n",
      "Q 349+74  T 423  \u001b[92m☑\u001b[0m 423 \n",
      "Q 168+85  T 253  \u001b[92m☑\u001b[0m 253 \n",
      "Q 82+161  T 243  \u001b[92m☑\u001b[0m 243 \n",
      "Q 962+78  T 1040 \u001b[92m☑\u001b[0m 1040\n",
      "Q 3+459   T 462  \u001b[92m☑\u001b[0m 462 \n",
      "Q 26+449  T 475  \u001b[92m☑\u001b[0m 475 \n",
      "Q 15+893  T 908  \u001b[92m☑\u001b[0m 908 \n",
      "Q 461+96  T 557  \u001b[92m☑\u001b[0m 557 \n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 30):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "             batch_size=BATCH_SIZE,\n",
    "             epochs=1,\n",
    "             validation_data=(x_val, y_val))\n",
    "    \n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        \n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if INVERT else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A precondition for the above method is that it assumes that a given fixed-length sequence may yield a fixed-length target [... t] sequence when input [... t].\n",
    "\n",
    "This works in some situations, but not in most usage scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
