{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use jieba word tokenizer\n",
    "\n",
    "![tag-cloud](https://ithelp.ithome.com.tw/upload/images/20171219/20107576LXAdzuZue5.png)\n",
    "本文參考:https://github.com/erhwenkuo/deep-learning-with-keras-notebooks/blob/master/8.1-jieba-word-tokenizer.ipynb\n",
    "\n",
    "Note: 本文主要修改與擷取了[林志傑-如何使用 JIEBA 結巴中文分詞程式](http://blog.fukuball.com/ru-he-shi-yong-jieba-jie-ba-zhong-wen-fen-ci-cheng-shi/)的內容。文字雲的圖像來源為[GoatWang-2018 iT 邦幫忙鐵人賽](https://ithelp.ithome.com.tw/articles/10192043?sc=rss.qu)。\n",
    "<br>\n",
    "\n",
    "對中文的斷詞有興趣強烈建議可以參考:[中文斷詞：斷句不要悲劇](https://speakerdeck.com/fukuball/head-first-chinese-text-segmentation)\n",
    "<br>\n",
    "\n",
    "本文主要是為了後續介詔word2vec的理論與實作的前置準備。\n",
    "\n",
    "自然語言處理(Natural Language Processing)的其中一個重要環節就是中文斷詞的處理，比起英文斷詞，中文斷詞在先天上就比較難處理，比如電腦要怎麼知道「全台大停電」要斷詞成「全台 / 大 / 停電」呢？如果是英文「Power outage all over Taiwan」，就可以直接用空白字元來斷成「Power / outage / all / over / Taiwan」，可見中文斷詞真的是一個大問題啊～!\n",
    "\n",
    "\n",
    "[结巴 (jieba) 中文分詞](https://github.com/fxsjy/jieba)是很好很簡單使用的Python中文分詞函式庫。 它有以下的特色:\n",
    "\n",
    "* 支持三種分詞模式：\n",
    "  * 精確模式，試圖將句子最精確地切開，適合文本分析。\n",
    "  * 全模式，把句子中所有的可以成詞的詞語都掃描出來，速度非常快，但是不能解決歧義。\n",
    "  * 搜索引擎模式，在精確模式的基礎上，對長詞再次切分，提高召回率，適合用於搜索引擎分詞。\n",
    "* 支持繁體分詞\n",
    "* 支持自定義詞典\n",
    "* MIT授權協議\n",
    "\n",
    "jieba中文斷詞所使用的演算法是基於 Trie Tree 結構去生成句子中中文字所有可能成詞的情況，然後使用動態規劃（Dynamic programming）算法來找出最大機率的路徑，這個路徑就是基於詞頻的最大斷詞結果。對於辨識新詞（字典詞庫中不存在的詞）則使用了 HMM 模型（Hidden Markov Model）及 Viterbi 算法來辨識出來。\n",
    "\n",
    "在[中文斷詞-by Mark Chang](https://www.slideshare.net/ckmarkohchang/chinese-words-segmentation-tutorial)的分享裡有詳細的解說。\n",
    "\n",
    "## install jieba\n",
    "pip install jieba\n",
    "\n",
    "## 基本斷詞用法，使用預設詞庫\n",
    "三種分詞模式示範：\n",
    "\n",
    "* 精確模式，試圖將句子最精確地切開，適合文本分析。\n",
    "* 全模式，把句子中所有的可以成詞的詞語都掃描出來，速度非常快，但是不能解決歧義。\n",
    "* 搜索引擎模式，在精確模式的基礎上，對長詞再次切分，提高召回率，適合用於搜索引擎分詞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"我是統粉我驕傲\"\n",
    "string2 = \"還敢下來啊，冰鳥\"\n",
    "string3 = ('我..我對於質疑我AD實力的人，我真的很佩服他們的想法，'\n",
    "           '你看我玩AD那個走位、那個觀念，在後面那個抖動、那個位移、那個操作，'\n",
    "           '說我不會玩AD?我這場就要給大家，看我會不會玩AD，我玩AD，基本上，'\n",
    "           '先贏50%、先贏50%，好啦，我也不要講先贏50%，先贏50%大家可能誤會什麼意思，'\n",
    "           '就是75%嘛！百分之五十乘百分之五十嘛！就百分之25嘛！再加上原本的百分之50，百分之75嘛，勝率的保證~')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全模式: 我/ 是/ 統/ 粉/ 我/ 驕/ 傲\n",
      "\n",
      "精確模式: 我/ 是/ 統粉/ 我/ 驕傲\n",
      "\n",
      "精確模式(預設): 還敢/ 下來/ 啊/ ，/ 冰鳥\n",
      "\n",
      "搜索引擎模式模式: 我/ ../ 我/ 對/ 於/ 質疑/ 我/ AD/ 實力/ 的/ 人/ ，/ 我/ 真的/ 很/ 佩服/ 他們/ 的/ 想法/ ，/ 你/ 看/ 我/ 玩/ AD/ 那個/ 走位/ 、/ 那個/ 觀念/ ，/ 在後面/ 那個/ 抖動/ 、/ 那個/ 位移/ 、/ 那個/ 操作/ ，/ 說/ 我/ 不會/ 玩/ AD/ ?/ 我/ 這場/ 就要/ 給/ 大家/ ，/ 看/ 我會/ 不會/ 玩/ AD/ ，/ 我/ 玩/ AD/ ，/ 基本/ 基本上/ ，/ 先贏/ 50%/ 、/ 先贏/ 50%/ ，/ 好/ 啦/ ，/ 我/ 也/ 不要/ 講先贏/ 50%/ ，/ 先贏/ 50%/ 大家/ 可能/ 誤會/ 什麼/ 意思/ ，/ 就是/ 75%/ 嘛/ ！/ 百分/ 五十/ 百分之/ 百分之五十/ 乘/ 百分/ 五十/ 百分之/ 百分之五十/ 嘛/ ！/ 就/ 百分/ 百分之/ 25/ 嘛/ ！/ 再/ 加上/ 原本/ 的/ 百分/ 百分之/ 50/ ，/ 百分/ 百分之/ 75/ 嘛/ ，/ 勝率/ 的/ 保證/ ~\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(string, cut_all=True)\n",
    "print(\"全模式: \" + \"/ \".join(seg_list))  # 全模式\n",
    "print()\n",
    "\n",
    "seg_list = jieba.cut(string, cut_all=False)\n",
    "print(\"精確模式: \" + \"/ \".join(seg_list))  # 精確模式\n",
    "print()\n",
    "\n",
    "seg_list = jieba.cut(string2)  # 預設為精確模式\n",
    "print(\"精確模式(預設): \" +\"/ \".join(seg_list))\n",
    "print()\n",
    "\n",
    "seg_list = jieba.cut_for_search(string3)  # 搜索引擎模式\n",
    "print(\"搜索引擎模式模式: \" +\"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "據原作者的說法，使用預設詞庫的話，繁體中文的斷詞結果應該會比較差，畢竟原來的詞庫是簡體中文。我們接下來試試看中文歌詞的斷詞結果如何。\n",
    "現在我們使用  華語樂壇之神—**周杰倫**的 **以父之名**\n",
    "的歌詞作為中文斷詞測試範例，歌詞我們先做成一個純文字檔lyric.txt置放到跟這個jupyter notebook相同的目錄下。\n",
    "內容如下\n",
    "> 微涼的晨露 沾濕黑禮服 石板路有霧 父在低訴\n",
    "無奈的覺悟 只能更殘酷 一切都為了 通往聖堂的路\n",
    "吹不散的霧 隱沒了意圖 誰輕柔踱步 停住\n",
    "還來不及哭 穿過的子彈 就帶走 溫度\n",
    "\n",
    "> 我們每個人都有罪 犯著不同的罪 我能決定誰對\n",
    "誰又該要沈睡 爭論不能解決 在永無止境的夜\n",
    "關掉你的嘴 唯一的恩惠\n",
    "擋在前面的人都有罪 後悔也無路可退 以父之名判決\n",
    "那感覺沒有適合字彙 就像邊笑邊掉淚 凝視著完全的黑\n",
    "阻擋悲劇蔓延的悲劇會讓我沈醉\n",
    "\n",
    "> 低頭親吻我的左手 換取被寬恕的承諾\n",
    "老舊管風琴在角落 一直一直一直伴奏\n",
    "黑色簾幕被風吹動陽光無言的穿透 灑向那群被我馴服後的獸\n",
    "沈默的喊叫 沈默的喊叫 孤單開始發酵 不停對著我嘲笑\n",
    "回憶逐漸延燒\n",
    "曾經純真的畫面 殘忍的溫柔出現 脆弱時間到\n",
    "我們一起來禱告\n",
    "\n",
    "> 仁慈的父我已墜入 看不見罪的國度 請原諒我的自負\n",
    "沒人能說沒人可說 好難承受 榮耀的背後刻著一道孤獨\n",
    "閉上雙眼 我又看見 當年那夢的畫面 天空是濛濛的霧\n",
    "父親牽著 我的雙手 輕輕走過 清晨那安安靜靜的石板路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精確模式: 微涼/ 的/ 晨露/  / 沾濕/ 黑禮服/  / 石板路/ 有霧/  / 父在/ 低訴/ \n",
      "/ 無奈/ 的/ 覺悟/  / 只能/ 更/ 殘酷/  / 一切/ 都/ 為/ 了/  / 通往/ 聖堂/ 的/ 路/ \n",
      "/ 吹不散/ 的/ 霧/  / 隱/ 沒/ 了/ 意圖/  / 誰/ 輕柔/ 踱步/  / 停住/ \n",
      "/ 還來/ 不及/ 哭/  / 穿過/ 的/ 子彈/  / 就/ 帶/ 走/  / 溫度/ \n",
      "/ \n",
      "/ 我們/ 每個/ 人/ 都/ 有罪/  / 犯著/ 不同/ 的/ 罪/  / 我能/ 決定/ 誰/ 對/ \n",
      "/ 誰/ 又/ 該/ 要/ 沈睡/  / 爭論/ 不能/ 解決/  / 在/ 永/ 無/ 止境/ 的/ 夜/ \n",
      "/ 關掉/ 你/ 的/ 嘴/  / 唯一/ 的/ 恩惠/ \n",
      "/ 擋/ 在/ 前面/ 的/ 人/ 都/ 有罪/  / 後/ 悔/ 也/ 無路/ 可退/  / 以父之名/ 判決/ \n",
      "/ 那感覺/ 沒有/ 適合字/ 彙/  / 就/ 像/ 邊笑邊/ 掉/ 淚/  / 凝視/ 著/ 完全/ 的/ 黑/ \n",
      "/ 阻擋/ 悲劇/ 蔓延/ 的/ 悲劇會/ 讓/ 我/ 沈醉/ \n",
      "/ \n",
      "/ 低頭親/ 吻/ 我/ 的/ 左手/  / 換取/ 被/ 寬/ 恕/ 的/ 承諾/ \n",
      "/ 老舊/ 管風琴/ 在/ 角落/  / 一直/ 一直/ 一直/ 伴奏/ \n",
      "/ 黑色/ 簾幕/ 被/ 風吹動陽光/ 無言/ 的/ 穿透/  / 灑向/ 那群/ 被/ 我/ 馴服/ 後/ 的/ 獸/ \n",
      "/ 沈默/ 的/ 喊叫/  / 沈默/ 的/ 喊叫/  / 孤單/ 開始/ 發酵/  / 不停/ 對/ 著/ 我/ 嘲笑/ \n",
      "/ 回憶/ 逐漸/ 延燒/ \n",
      "/ 曾/ 經純/ 真的/ 畫面/  / 殘忍/ 的/ 溫柔/ 出現/  / 脆弱/ 時間/ 到/ \n",
      "/ 我們/ 一起/ 來/ 禱告/ \n",
      "/ \n",
      "/ 仁慈/ 的/ 父/ 我/ 已/ 墜入/  / 看不見/ 罪/ 的/ 國度/  / 請/ 原諒/ 我/ 的/ 自負/ \n",
      "/ 沒人能/ 說/ 沒人/ 可/ 說/  / 好難/ 承受/  / 榮耀/ 的/ 背後刻/ 著/ 一道/ 孤獨/ \n",
      "/ 閉上/ 雙眼/  / 我/ 又/ 看/ 見/  / 當年/ 那/ 夢/ 的/ 畫面/  / 天空/ 是/ 濛濛/ 的/ 霧/ \n",
      "/ 父親/ 牽著/  / 我/ 的/ 雙手/  / 輕輕/ 走過/  / 清晨/ 那/ 安安/ 靜靜/ 的/ 石板路/ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "content = open('lyric.txt', 'r').read()\n",
    "\n",
    "seg_list = jieba.cut(content, cut_all=False)\n",
    "print(\"精確模式: \" + \"/ \".join(seg_list))  # 精確模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以從結果看出斷詞已經開始出了一些問題，比如「低頭親吻」被斷成了「低頭親/ 吻」，這應該就是因為預設詞庫是簡體中文所造成，因此繁體中文的斷詞結果會比較差，還好 jieba 也提供了可以切換詞庫的功能，並提供了一個繁體中文詞庫，所以我們可以使用切換詞庫的功能來改善斷詞結果。\n",
    "\n",
    "## 中文歌詞斷詞，使用繁體詞庫\n",
    "從 https://github.com/fxsjy/jieba/blob/master/extra_dict/dict.txt.big 下載繁體詞庫檔，置放到跟這個jupyter notebook相同的目錄下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\Program\\model\\jieba\\dict.txt.big.txt ...\n",
      "Dumping model to file cache C:\\Users\\user\\AppData\\Local\\Temp\\jieba.u5f50f2b7ab381204f5f6032f217b280e.cache\n",
      "Loading model cost 1.505 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精確模式: 微涼/ 的/ 晨露/  / 沾/ 濕/ 黑/ 禮服/  / 石板路/ 有霧/  / 父在/ 低訴/ \n",
      "/ 無奈/ 的/ 覺悟/  / 只能/ 更/ 殘酷/  / 一切/ 都/ 為/ 了/  / 通往/ 聖堂/ 的/ 路/ \n",
      "/ 吹不散/ 的/ 霧/  / 隱沒/ 了/ 意圖/  / 誰/ 輕柔/ 踱步/  / 停住/ \n",
      "/ 還/ 來不及/ 哭/  / 穿過/ 的/ 子彈/  / 就/ 帶走/  / 溫度/ \n",
      "/ \n",
      "/ 我們/ 每個/ 人/ 都/ 有罪/  / 犯著/ 不同/ 的/ 罪/  / 我能/ 決定/ 誰/ 對/ \n",
      "/ 誰/ 又/ 該/ 要/ 沈睡/  / 爭論/ 不能/ 解決/  / 在/ 永無止境/ 的/ 夜/ \n",
      "/ 關掉/ 你/ 的/ 嘴/  / 唯一/ 的/ 恩惠/ \n",
      "/ 擋/ 在/ 前面/ 的/ 人/ 都/ 有罪/  / 後悔/ 也/ 無路/ 可退/  / 以父之名/ 判決/ \n",
      "/ 那/ 感覺/ 沒有/ 適合/ 字彙/  / 就/ 像/ 邊笑邊/ 掉淚/  / 凝視/ 著/ 完全/ 的/ 黑/ \n",
      "/ 阻擋/ 悲劇/ 蔓延/ 的/ 悲劇/ 會/ 讓/ 我/ 沈醉/ \n",
      "/ \n",
      "/ 低頭/ 親吻/ 我/ 的/ 左手/  / 換取/ 被/ 寬恕/ 的/ 承諾/ \n",
      "/ 老舊/ 管風琴/ 在/ 角落/  / 一直/ 一直/ 一直/ 伴奏/ \n",
      "/ 黑色/ 簾幕/ 被/ 風吹/ 動/ 陽光/ 無言/ 的/ 穿透/  / 灑向/ 那群/ 被/ 我/ 馴服/ 後/ 的/ 獸/ \n",
      "/ 沈默/ 的/ 喊叫/  / 沈默/ 的/ 喊叫/  / 孤單/ 開始/ 發酵/  / 不停/ 對/ 著/ 我/ 嘲笑/ \n",
      "/ 回憶/ 逐漸/ 延燒/ \n",
      "/ 曾經/ 純真/ 的/ 畫面/  / 殘忍/ 的/ 溫柔/ 出現/  / 脆弱/ 時間/ 到/ \n",
      "/ 我們/ 一/ 起來/ 禱告/ \n",
      "/ \n",
      "/ 仁慈/ 的/ 父/ 我/ 已/ 墜入/  / 看不見/ 罪/ 的/ 國度/  / 請原諒/ 我/ 的/ 自負/ \n",
      "/ 沒人能/ 說/ 沒人/ 可說/  / 好難/ 承受/  / 榮耀/ 的/ 背後/ 刻著/ 一道/ 孤獨/ \n",
      "/ 閉上/ 雙眼/  / 我/ 又/ 看見/  / 當年/ 那夢/ 的/ 畫面/  / 天空/ 是/ 濛濛/ 的/ 霧/ \n",
      "/ 父親/ 牽著/  / 我/ 的/ 雙手/  / 輕輕/ 走過/  / 清晨/ 那/ 安安靜靜/ 的/ 石板路/ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 指定使用繁體詞庫\n",
    "dict_path = \"D:/Program/model/jieba/\"\n",
    "jieba.set_dictionary(dict_path+'dict.txt.big.txt') \n",
    "\n",
    "content = open('lyric.txt', 'r').read()\n",
    "\n",
    "seg_list = jieba.cut(content, cut_all=False)\n",
    "print(\"精確模式: \" + \"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們在程式中多加一行 `jieba.set_dictionary('dict.txt.big')`，這樣就可以將斷詞詞庫切換到 dic.txt.big 這個檔案。\n",
    "「低頭親/吻」被正確斷詞成「低頭/ 親吻」\n",
    "\n",
    "# Reference\n",
    "* [林志傑-如何使用 JIEBA 結巴中文分詞程式](http://blog.fukuball.com/ru-he-shi-yong-jieba-jie-ba-zhong-wen-fen-ci-cheng-shi/)\n",
    "* [结巴中文分词Github](https://github.com/fxsjy/jieba)\n",
    "* [中文斷詞：斷句不要悲劇](https://speakerdeck.com/fukuball/head-first-chinese-text-segmentation)\n",
    "* [結巴斷詞器與FastTag](http://blog.pulipuli.info/2017/11/fasttag-identify-part-of-speech-in.html)\n",
    "* [中文自然語言處理基礎](https://ithelp.ithome.com.tw/articles/10192043?sc=rss.qu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
