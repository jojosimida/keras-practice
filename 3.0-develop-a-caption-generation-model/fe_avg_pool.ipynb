{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from pickle import load, dump\n",
    "from IPython.display import Image\n",
    "import os\n",
    " \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, LSTM\n",
    "from keras.layers import RepeatVector, TimeDistributed\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "\n",
    "from caption_generation_model_API import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 6000\n",
      "Descriptions: train=5500, test=500\n",
      "Photos: train=5500, test=500\n",
      "Vocabulary Size: 3699\n",
      "Description Length: 30\n"
     ]
    }
   ],
   "source": [
    "path = 'D:/Program/dataset/Flickr8K/'\n",
    "\n",
    "# load dev set\n",
    "filename = path + 'Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "dataset = load_set(filename)\n",
    "print('Dataset: {}'.format(len(dataset)))\n",
    "# train-test split\n",
    "train, test = train_test_split(dataset)\n",
    "# descriptions\n",
    "train_descriptions = load_clean_descriptions(path+'descriptions.txt', train)\n",
    "test_descriptions = load_clean_descriptions(path+'descriptions.txt', test)\n",
    "print('Descriptions: train={}, test={}'.format(len(train_descriptions), len(test_descriptions)))\n",
    "# photo features\n",
    "train_features = load_photo_features(path+'features.pkl', train)\n",
    "test_features = load_photo_features(path+'features.pkl', test)\n",
    "print('Photos: train={}, test={}'.format(len(train_features), len(test_features)))\n",
    "# prepare tokenizer\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: {}'.format(vocab_size))\n",
    "# determine the maximum sequence length\n",
    "max_length = max(len(s.split()) for s in list(train_descriptions.values()))\n",
    "print('Description Length: {}'.format(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "n_epochs = 500\n",
    "n_photos_per_update = 2\n",
    "n_batches_per_epoch = int(len(train) / n_photos_per_update)\n",
    "n_repeats = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_and_print(model, descriptions, photos, tokenizer, max_length):\n",
    "    actual, predicted = list(), list()\n",
    "    # step over the whole set\n",
    "    for key, desc in descriptions.items():\n",
    "        # generate description\n",
    "        yhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
    "        # store actual and predicted\n",
    "        actual.append([desc.split()])\n",
    "        predicted.append(yhat.split())\n",
    "        print('Actual:    {}'.format(desc))\n",
    "        print('Predicted: {}'.format(yhat))\n",
    "        print()\n",
    "        if len(actual) >= 50:\n",
    "            break\n",
    "    # calculate BLEU score\n",
    "    bleu = corpus_bleu(actual, predicted)\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"D:/Program/train_model/image_caption/fe_avg_pool/fe_avg_pool.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 7, 7, 512)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 512)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 30, 50)       184950      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          65664       global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 30, 256)      314368      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 30, 128)      0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 30, 128)      32896       lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 30, 256)      0           repeat_vector_2[0][0]            \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 500)          1514000     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 500)          250500      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3699)         1853199     dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,215,577\n",
      "Trainable params: 4,215,577\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:    startseq child in pink dress is climbing up set of stairs in an entry way endseq\n",
      "Predicted: startseq blue of people in black fall hovering endseq\n",
      "\n",
      "Actual:    startseq black dog and spotted dog are fighting endseq\n",
      "Predicted: startseq black and white dog is running on over endseq\n",
      "\n",
      "Actual:    startseq little girl covered in paint sits in front of painted rainbow with her hands in bowl endseq\n",
      "Predicted: startseq boy is riding on the stands endseq\n",
      "\n",
      "Actual:    startseq man lays on bench while his dog sits by him endseq\n",
      "Predicted: startseq man in red shirt is snowy pants on the shore endseq\n",
      "\n",
      "Actual:    startseq man in an orange hat starring at something endseq\n",
      "Predicted: startseq man in group shirt and each and half hat and hat is smiling endseq\n",
      "\n",
      "Actual:    startseq child playing on rope net endseq\n",
      "Predicted: startseq blue of runs are running on the waterskies picture endseq\n",
      "\n",
      "Actual:    startseq black and white dog is running in grassy garden surrounded by white fence endseq\n",
      "Predicted: startseq brown dog is running on the swing endseq\n",
      "\n",
      "Actual:    startseq dog shakes its head near the shore red ball next to it endseq\n",
      "Predicted: startseq dog is running on the beach endseq\n",
      "\n",
      "Actual:    startseq boy smiles in front of stony wall in city endseq\n",
      "Predicted: startseq man is standing on the terrier of building endseq\n",
      "\n",
      "Actual:    startseq black dog leaps over log endseq\n",
      "Predicted: startseq brown dog is running on the swing endseq\n",
      "\n",
      "Actual:    startseq brown and white dog is running through the snow endseq\n",
      "Predicted: startseq dog is skater through the over endseq\n",
      "\n",
      "Actual:    startseq man in hat is displaying pictures next to skier in blue hat endseq\n",
      "Predicted: startseq man is walking on the beach endseq\n",
      "\n",
      "Actual:    startseq collage of one person climbing cliff endseq\n",
      "Predicted: startseq man is mountain up rock endseq\n",
      "\n",
      "Actual:    startseq brown dog chases the water from sprinkler on lawn endseq\n",
      "Predicted: startseq black and white dog is running on the sidewalk endseq\n",
      "\n",
      "Actual:    startseq dog prepares to catch thrown object in field with nearby cars endseq\n",
      "Predicted: startseq dog is jumping through the over endseq\n",
      "\n",
      "Actual:    startseq black and white dog jumping in the air to get toy endseq\n",
      "Predicted: startseq dog is jumping on the over endseq\n",
      "\n",
      "Actual:    startseq couple and an infant being held by the male sitting next to pond with near by stroller endseq\n",
      "Predicted: startseq man in black shirt is standing on the beach endseq\n",
      "\n",
      "Actual:    startseq black dog running in the surf endseq\n",
      "Predicted: startseq black and white dog is running through the water endseq\n",
      "\n",
      "Actual:    startseq man drilling hole in the ice endseq\n",
      "Predicted: startseq man in red hill is standing on the against endseq\n",
      "\n",
      "Actual:    startseq two different breeds of brown and white dogs play on the beach endseq\n",
      "Predicted: startseq dog is standing on the beach endseq\n",
      "\n",
      "Actual:    startseq man uses ice picks and crampons to scale ice endseq\n",
      "Predicted: startseq man in red shirt is in the snow endseq\n",
      "\n",
      "Actual:    startseq black dog carries green toy in his mouth as he walks through the grass endseq\n",
      "Predicted: startseq black dog is running through the over endseq\n",
      "\n",
      "Actual:    startseq man and baby are in yellow kayak on water endseq\n",
      "Predicted: startseq narrow man is in drives in wheeler in end endseq\n",
      "\n",
      "Actual:    startseq black dog and brown dog are jumping up to catch red toy endseq\n",
      "Predicted: startseq black dog is running on the over endseq\n",
      "\n",
      "Actual:    startseq man in black is sitting next to modern art structure in front of glass building endseq\n",
      "Predicted: startseq man is jumping on men endseq\n",
      "\n",
      "Actual:    startseq tent is being set up on the ice endseq\n",
      "Predicted: startseq woman is walking on the the bicycle of the the carrying beach endseq\n",
      "\n",
      "Actual:    startseq man is standing in front of skyscraper endseq\n",
      "Predicted: startseq man in red shirt is standing on the beach endseq\n",
      "\n",
      "Actual:    startseq people sit on the mountainside and check out the view endseq\n",
      "Predicted: startseq people sit on community in front of colored endseq\n",
      "\n",
      "Actual:    startseq boy in green shirt is looking down at many inflatable boats endseq\n",
      "Predicted: startseq man is riding down enclosure playground endseq\n",
      "\n",
      "Actual:    startseq man and woman pose for the camera while another man looks on endseq\n",
      "Predicted: startseq man in red shirt is standing on the beach endseq\n",
      "\n",
      "Actual:    startseq couple of several people sitting on ledge overlooking the beach endseq\n",
      "Predicted: startseq man is splashing around the end endseq\n",
      "\n",
      "Actual:    startseq boy takes jump on his skateboard while another boy with skateboard watches endseq\n",
      "Predicted: startseq man is jumping on collie endseq\n",
      "\n",
      "Actual:    startseq girl paddling down large river as seen from behind her endseq\n",
      "Predicted: startseq man in black hill is standing on smooth surrounded endseq\n",
      "\n",
      "Actual:    startseq girl in pigtails splashes in the shallow water endseq\n",
      "Predicted: startseq boy in black and white hill is running on smooth water endseq\n",
      "\n",
      "Actual:    startseq group of four children wearing pajamas have pillow fight endseq\n",
      "Predicted: startseq man in red shirt is standing on the beach endseq\n",
      "\n",
      "Actual:    startseq two constructions workers sit on beam taking break endseq\n",
      "Predicted: startseq religious man salon endseq\n",
      "\n",
      "Actual:    startseq little girl looking at brochure on train rides endseq\n",
      "Predicted: startseq boy is sitting on the so drinks endseq\n",
      "\n",
      "Actual:    startseq brown dog is running after black dog on rocky shore endseq\n",
      "Predicted: startseq brown dog is running through the carrying field endseq\n",
      "\n",
      "Actual:    startseq boy descends off the end of high diving board endseq\n",
      "Predicted: startseq man is resting on the water endseq\n",
      "\n",
      "Actual:    startseq guy stands by window taking his overshirt off endseq\n",
      "Predicted: startseq man is standing on the knife of another boy endseq\n",
      "\n",
      "Actual:    startseq lightcolored dog runs on the beach endseq\n",
      "Predicted: startseq upsidedown dog is running on the beach endseq\n",
      "\n",
      "Actual:    startseq hiker standing high on bluff overlooking the mountains below endseq\n",
      "Predicted: startseq hiker gardening through carrying trick endseq\n",
      "\n",
      "Actual:    startseq black and white dog is attempting to catch yellow and purple object in low cut yard endseq\n",
      "Predicted: startseq black and white dog is running on over endseq\n",
      "\n",
      "Actual:    startseq man in blue shorts is laying in the street endseq\n",
      "Predicted: startseq lot ship in the purse endseq\n",
      "\n",
      "Actual:    startseq white and black dog and brown dog in sandy terrain endseq\n",
      "Predicted: startseq dog is skater on coffee endseq\n",
      "\n",
      "Actual:    startseq black and white dog catches toy in midair endseq\n",
      "Predicted: startseq black and white dog is running through over endseq\n",
      "\n",
      "Actual:    startseq crowd watching air balloons at night endseq\n",
      "Predicted: startseq crowd players jewelry poodle at gray endseq\n",
      "\n",
      "Actual:    startseq child with helmet on his head rides bike endseq\n",
      "Predicted: startseq man is moving on the sidewalk endseq\n",
      "\n",
      "Actual:    startseq man in brown shirt and dark shorts plays on the beach with his two black dogs endseq\n",
      "Predicted: startseq man is standing tunnel the beach endseq\n",
      "\n",
      "Actual:    startseq boy cleans the bubbles off his face endseq\n",
      "Predicted: startseq man is in the dirt endseq\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07507702587419578"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_score = evaluate_and_print(model, train_descriptions, train_features, tokenizer, max_length)\n",
    "trainset_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
