{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter image recognition\n",
    "\n",
    "![pic](https://imgur.com/qBl14zL.png)\n",
    "\n",
    "Download\n",
    "\n",
    "[Kaggle Dataset](https://www.kaggle.com/c/street-view-getting-started-with-julia/data)\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### Image Color\n",
    "Almost all images in training and test data sets are color images. The first step in preprocessing is to convert all the images to grayscale. It simplifies the data that is entered into the network and also allows the model to be more generalized, since a blue letter and a red letter are the same for the classification of this image. Therefore, this preprocessing to reduce the channel of the image color should have no negative effect on the final accuracy, as most of the text is highly contrasting with the background.\n",
    "\n",
    "### Image Resizing\n",
    "Since the images have different shapes and sizes, we have to normalize the images so that we can determine the model's input. There are two major issues that need to be addressed in this process: Which image size do we choose? Should we keep the image aspect ratio?\n",
    "\n",
    "At first, I also thought it would be better to keep the aspect ratio of the image as it would not distort the image. This can also lead to confusion between O and O (uppercase o and zero). However, after some testing, it seems that the model does not maintain the aspect ratio better.\n",
    "\n",
    "With respect to image size, a 16 × 16 image allows very fast training but does not give the best results. These small images are the perfect choice for quick test ideas. The use of 32 × 32 images makes training quick and provides good accuracy. Finally, the use of a 64x64 image made the training considerably slower and slightly improved than the 32x32 image. I chose to use 32 × 32 images because it is the best compromise between speed and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Program/dataset/First Steps With Julia/trainPreproc'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import Image\n",
    "\n",
    "path = \"D:/Program/dataset/First Steps With Julia\"\n",
    "\n",
    "# The target size after image conversion\n",
    "img_height, img_width = 32, 32\n",
    "\n",
    "# Save the directory after converting the image\n",
    "suffix = \"Preproc\"\n",
    "trainDataPath = path + \"/train\" + suffix\n",
    "testDataPath = path + \"/test\" + suffix\n",
    "\n",
    "# create directory\n",
    "if not os.path.exists(trainDataPath):\n",
    "    os.makedirs(trainDataPath)\n",
    "\n",
    "if not os.path.exists(testDataPath):\n",
    "    os.makedirs(testDataPath)\n",
    "    \n",
    "trainDataPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (6283, 32, 32)\n",
      "After:  (6283, 32, 32, 1)\n",
      "Before:  (6220, 32, 32)\n",
      "After:  (6220, 32, 32, 1)\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Image size and image color preprocessing ###\n",
    "\n",
    "for datasetType in [\"train\",\"test\"]:\n",
    "    # ordered the datapath, use \"key=os.path.getmtime\"\n",
    "    imgFiles = sorted(glob.glob(path + \"/\" + datasetType + \"/*.bmp\"), key=os.path.getmtime)\n",
    "    imgData = np.zeros((len(imgFiles), img_height, img_width))\n",
    "    \n",
    "    for i, imgFilePath in enumerate(imgFiles):\n",
    "        # Image Color processing, to gray scale\n",
    "        img_gray = cv2.imread(imgFilePath,0)        \n",
    "        imgResized = cv2.resize(img_gray, (img_height, img_width))\n",
    "        imgData[i] = imgResized\n",
    "        \n",
    "        # get the basename, ex: 1.Bmp or 6284.Bmp\n",
    "        filename = os.path.basename(imgFilePath)\n",
    "        filenameDotSplit = filename.split(\".\")\n",
    "        \n",
    "        # zfill, ex: 00001.bmp or 06284.bmp\n",
    "        newFilename = filenameDotSplit[0].zfill(5) + \".\" + filenameDotSplit[-1].lower()\n",
    "        newFilepath = path + \"/\" + datasetType + suffix + \"/\" + newFilename\n",
    "        cv2.imwrite(newFilepath, imgResized)\n",
    "\n",
    "    # add the dimension of \"Channel\"\n",
    "    print(\"Before: \", imgData.shape)\n",
    "    imgData = imgData[:,:,:,np.newaxis] \n",
    "    print(\"After: \", imgData.shape)\n",
    "    \n",
    "    # Data standardization\n",
    "    imgData = imgData.astype('float32')/255\n",
    "    \n",
    "    # Save the image converted ndarray object as a numpy object to the file system\n",
    "    np.save(path + \"/\" + datasetType + suffix + \".npy\", imgData)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Conversion\n",
    "We also have to convert one-hot encoding of the character's label. It is necessary to provide tag information to the CNN neural network. This process consists of two steps. First, we convert characters to consecutive integers. Since the characters to be predicted are [0 ~ 9], [a ~ z] and [A ~ Z] are 62 characters in total, we will assign each character to an integer from [0 to 61].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "def label2int(ch):\n",
    "    # Given a string representing one Unicode character, \n",
    "    # return an integer representing the Unicode code point of that character. \n",
    "    asciiVal = ord(ch)\n",
    "    if(asciiVal<=57): #0-9\n",
    "        asciiVal-=48\n",
    "    elif(asciiVal<=90): #A-Z\n",
    "        asciiVal-=55\n",
    "    else: #a-z\n",
    "        asciiVal-=61\n",
    "    return asciiVal\n",
    "    \n",
    "def int2label(i):\n",
    "    if(i<=9): #0-9\n",
    "        i+=48\n",
    "    elif(i<=35): #A-Z\n",
    "        i+=55\n",
    "    else: #a-z\n",
    "        i+=61\n",
    "    return chr(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['n', '8', 'T', ..., 'P', 'N', 'R'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep \"label information\" column\n",
    "y_train = pd.read_csv(path + \"/trainLabels.csv\").values[:,1] \n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for the label\n",
    "\n",
    "# A-Z, a-z, 0-9, there are 62 categories\n",
    "Y_train = np.zeros((y_train.shape[0], 62)) \n",
    "\n",
    "for i in range(y_train.shape[0]):\n",
    "    Y_train[i][label2int(y_train[i])] = 1 # One-hot\n",
    "\n",
    "# The converted label (Label) data stored in the file system for subsequent rapid loading and processing\n",
    "np.save(path + \"/\" + \"labelsPreproc.npy\", Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
